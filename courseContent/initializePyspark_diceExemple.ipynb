{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark\n",
    "\n",
    "Apache's framework for distributed processing\n",
    "\n",
    "- Initialisation Process\n",
    "\n",
    "- basic dice exemple\n",
    "\n",
    "---\n",
    "\n",
    "## guide\n",
    "\n",
    "\n",
    "nous vle konnen exactement mete en claire concept poun kember yo poun k travay avec spark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing a Spark program must do is to create a SparkContext object, which tells Spark how to access a cluster. To create a SparkContext you first need to build a SparkConf object that contains information about your application.\n",
    "\n",
    "The appName parameter is a name for your application to show on the cluster UI. master is a Spark, Mesos or YARN cluster URL, or a special “local” string to run in local mode. In practice, when running on a cluster, you will not want to hardcode master in the program, but rather launch the application with spark-submit and receive it there. However, for local testing and unit tests, you can pass “local” to run Spark in-process.\n",
    "\n",
    "\n",
    "> Heuresment pou nous msambler jwenn deux methode pou demarrer Spark sou machine la.\n",
    "\n",
    "Fok nous set driver/host computer a.\n",
    "\n",
    "\n",
    "\n",
    "key concepts for Spark:\n",
    "\n",
    "- RDD\n",
    "- transformer\n",
    "- action\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "master=\"local[3]\"\n",
    "appName=\"datamining-spark\"\n",
    "conf = SparkConf().set(\"spark.driver.host\",\"127.0.0.1\").setAppName(appName).setMaster(master)\n",
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "# That would work: SparkSession.builder.config('spark.driver.host', '127.0.0.1').getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .config('spark.driver.host', '127.0.0.1') \\\n",
    "    .master(\"local[1]\") \\\n",
    "    .appName(\"Word Count\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sparkSc = spark.sparkContext"
   ]
  },
  {
   "source": [
    "## Nou pral demarrer exemple Dice la."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rd \n",
    "n = 100\n",
    "rd.seed(1)\n",
    "simulations = range(100)\n",
    "\n"
   ]
  },
  {
   "source": [
    "- SC cluster/context"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headsc = (sc.parallelize(simulations)\n",
    "        .map(lambda _: rd.random())\n",
    "        .filter(lambda dice: dice<0.2)\n",
    "        .count()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(headsc)\n",
    "tails = n -headsc\n",
    "ratio = headsc / n\n",
    "print(f'number of tails: {tails}', f'ratio: {ratio}')"
   ]
  },
  {
   "source": [
    "- sparkSc cluster/context"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsp = (sparkSc.parallelize(simulations)\n",
    "        .map(lambda _: rd.random())\n",
    "        .filter(lambda dice: dice<0.3)\n",
    "        .count()\n",
    "    )\n",
    "\n",
    "print(hsp)\n",
    "t = n -hsp\n",
    "rat = hsp / n\n",
    "print(f'number of tails: {t}', f'ratio: {rat}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sparkSc.stop()\n",
    "#sc.stop()"
   ]
  },
  {
   "source": [
    "## Map VS FlatMap\n",
    "\n",
    "---"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile input.txt\n",
    "Hello world\n",
    "Another line\n",
    "Yet another line\n",
    "The last line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "mast=\"local[2]\"\n",
    "Name=\"mapVSflatmap\"\n",
    "con = SparkConf().set(\"spark.driver.host\",\"127.0.0.1\").setAppName(Name).setMaster(mast)\n",
    "spC = SparkContext(conf=con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can get access to the inut.txt\n",
    "spC.textFile(\"./input.txt\")\\\n",
    "    .map(lambda x: x.split()) \\\n",
    "        .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spC.textFile(\"./input.txt\")\\\n",
    "    .flatMap(lambda x: x.split()) \\\n",
    "        .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spC.stop()"
   ]
  },
  {
   "source": [
    "## PairRDD\n",
    "\n",
    "---"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "Mastery=\"local\"\n",
    "NameApp=\"PairRDD\"\n",
    "conn = SparkConf().set(\"spark.driver.host\",\"127.0.0.1\").setAppName(NameApp).setMaster(Mastery)\n",
    "sconn = SparkContext(conf=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Overwriting sales.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile sales.txt\n",
    "#ID DATE        STORE  PRODUCT AMOUNT\n",
    "100 12/13/2001  34     #345   375.43\n",
    "103 12/13/2004  31     #325   375.90\n",
    " 10 12/13/2011   3     #145    23.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['#ID DATE        STORE  PRODUCT AMOUNT',\n",
       " '100 12/13/2001  34     #345   375.43']"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "sconn.textFile(\"./sales.txt\")\\\n",
    "    .take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['103 12/13/2004  31     #325   375.90',\n",
       " '100 12/13/2001  34     #345   375.43']"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "sconn.textFile(\"./sales.txt\")\\\n",
    "    .top(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['#ID', 'DATE', 'STORE', 'PRODUCT', 'AMOUNT'],\n",
       " ['100', '12/13/2001', '34', '#345', '375.43']]"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "sconn.textFile(\"./sales.txt\")\\\n",
    "    .map(lambda x: x.split()) \\\n",
    "    .take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['100', '12/13/2001', '34', '#345', '375.43'],\n",
       " ['103', '12/13/2004', '31', '#325', '375.90']]"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "sconn.textFile(\"./sales.txt\")\\\n",
    "    .map(lambda x: x.split()) \\\n",
    "        .filter(lambda x: not x[0].startswith('#'))\\\n",
    "    .take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['DATE',\n",
       " 'STORE',\n",
       " 'PRODUCT',\n",
       " 'AMOUNT',\n",
       " '100',\n",
       " '12/13/2001',\n",
       " '34',\n",
       " '375.43',\n",
       " '103',\n",
       " '12/13/2004',\n",
       " '31',\n",
       " '375.90',\n",
       " '10',\n",
       " '12/13/2011',\n",
       " '3',\n",
       " '23.00']"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "sconn.textFile(\"./sales.txt\")\\\n",
    "    .flatMap(lambda x: x.split()) \\\n",
    "        .filter(lambda x: not x.startswith('#'))\\\n",
    "    .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['375.43', '375.90', '23.00']"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "sconn.textFile(\"./sales.txt\")\\\n",
    "    .map(lambda x: x.split()) \\\n",
    "        .filter(lambda x: not x[0].startswith('#'))\\\n",
    "        .map(lambda x: x[-1])\\\n",
    "    .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "774.3299999999999"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "sconn.textFile(\"./sales.txt\")\\\n",
    "    .map(lambda x: x.split()) \\\n",
    "        .filter(lambda x: not x[0].startswith('#'))\\\n",
    "        .map(lambda x: float(x[-1]))\\\n",
    "    .sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sconn.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}